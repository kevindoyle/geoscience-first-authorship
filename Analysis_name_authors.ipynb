{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "447d3b33",
   "metadata": {},
   "source": [
    "### This notebook looks at the number of papers each individual author publishes.\n",
    "\n",
    "It compares the probability of female and male authors to be among the top 10, 30, 100... most productive authors (both first and last authors).\n",
    "\n",
    "As input data it uses the records in directory author_allgenders.\n",
    "\n",
    "We can conclude here that men are generally more strongly represented among highly productive authors. This can be seen because the overall female quota of first authors, for example, is around 25 %, but it is only around 15 % among the most prolifically publishing authors. \n",
    "\n",
    "That this pattern appears both for first and for last authors means that there are structural factors that hold female seismologists back from publishing as much as their male colleagues.\n",
    "\n",
    "In the case of the first authors, this may be an illustration of the leaky pipeline. The frequency of female authors stabilizes at a number of papers per author of 2 over the past ten years. It may be hypothesized that these are papers by graduate students who left academia after their PhD. This indicates that the number of female seismologists in permanent positions is well below 25 %.\n",
    "\n",
    "For the last authors, it should be taken into account that female faculty are on the rise. Therefore, it is likely that female seismologists are more frequently young faculty that have taken up their appointments in recent years and have not yet had the possibility to publish senior-author papers as much as their male peers. However, there are thousands of last-authored papers by female seismologist authors that have only published one paper during the past ten years. These are unlikely to be the senior-authored works by supervising female faculty, and more likely to be contributions where the last author is simply a contributor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b25d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the follwoing packages in the enviroment:\n",
    "# python3 -m pip install pandas\n",
    "# python3 -m pip install seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import os\n",
    "\n",
    "from read_jsondata import read_jsons\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f1fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define local paths\n",
    "\n",
    "root = ! pwd\n",
    "root = root[0]\n",
    "\n",
    "RAW_DIR=root+\"/author_allgenders/\"  \n",
    "\n",
    "if not os.path.exists(RAW_DIR):\n",
    "    print(\"The directory {} does not exist.\\nThere is no raw data for statistical analysis.\".format(RAW_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525fe3d7",
   "metadata": {},
   "source": [
    "#### READ DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e39001",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_jsons(RAW_DIR, columns=['journal','all_names', 'all_genders','all_percent','year'])\n",
    "# I included cleaning names of journals and removing 2021 data into read_jsons\n",
    "# and also that impact factor is added\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83655785",
   "metadata": {},
   "source": [
    "##### Create new columns for statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d01457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First author's gender and percentage:\n",
    "\n",
    "df['First_Author'] = df['all_names'].apply(lambda x: x[0]) #take the first element of the list all_genders\n",
    "df['First_Author_gend'] = df['all_genders'].apply(lambda x: x[0]) #take the first element of the list all_genders\n",
    "df['First_Author_gendprob'] = df['all_percent'].apply(lambda x: x[0]) #take the first element of the list all_genders\n",
    "\n",
    "\n",
    "\n",
    "# Last author's gender and percentage:\n",
    "\n",
    "df['Last_Author'] = df['all_names'].apply(lambda x: x[-1]) #take the last element of the list all_genders\n",
    "df['Last_Author_gend'] = df['all_genders'].apply(lambda x: x[-1]) #take the last element of the list all_genders\n",
    "df['Last_Author_gendprob'] = df['all_percent'].apply(lambda x: x[-1]) #take the last element of the list all_genders\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa4fa94",
   "metadata": {},
   "source": [
    "##### Clean names just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba607b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clean_names(x):\n",
    "    first_name = x.split()[0] \n",
    "    last_name = x.split()[-1]\n",
    "    \n",
    "    name = first_name + ' ' + last_name\n",
    "    \n",
    "    return name\n",
    "\n",
    "\n",
    "df['First_Author_clean'] = df['First_Author'].apply(lambda x: Clean_names(x))\n",
    "df['Last_Author_clean'] = df['Last_Author'].apply(lambda x: Clean_names(x))\n",
    "\n",
    "df.drop(columns=['First_Author', 'Last_Author'],inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e04909",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Count number of papers for each author and create dictionary\n",
    "\n",
    "dict_last = df.Last_Author_clean.value_counts().to_dict()\n",
    "dict_first = df.First_Author_clean.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create new dataframes, one for first authors and another one for last authors\n",
    "\n",
    "df_first = df[['First_Author_clean','First_Author_gend','First_Author_gendprob', 'year']].copy()\n",
    "df_last = df[['Last_Author_clean','Last_Author_gend','Last_Author_gendprob', 'year']].copy()\n",
    "\n",
    "df_first['Num_papers'] = df_first.First_Author_clean.map(dict_first) # create new column with number of papers\n",
    "df_last['Num_papers'] = df_last.Last_Author_clean.map(dict_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba0f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop duplicated name and sort in descending order of num_papers\n",
    "\n",
    "df_first2 = df_first.drop_duplicates('First_Author_clean').sort_values(by=['Num_papers'],ascending=False).reset_index(drop = True)\n",
    "\n",
    "df_last2 = df_last.drop_duplicates('Last_Author_clean').sort_values(by=['Num_papers'],ascending=False).reset_index(drop = True)\n",
    "\n",
    "df_first2[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d07f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## It is easier to have all probabilities with respect to female\n",
    "\n",
    "# prob(female) = 1 - prob(male)\n",
    "\n",
    "# Prob first author female:\n",
    "\n",
    "df_first2['First_Author_probF'] = df_first2['First_Author_gendprob']\n",
    "\n",
    "df_first2.loc[df_first2['First_Author_gend'] == 'male','First_Author_probF'] = \\\n",
    "    1 - df_first2.loc[df_first2['First_Author_gend'] == 'male','First_Author_probF']\n",
    "\n",
    "# Prob last author female:\n",
    "\n",
    "df_last2['Last_Author_probF'] = df_last2['Last_Author_gendprob']\n",
    "\n",
    "df_last2.loc[df_last2['Last_Author_gend'] == 'male','Last_Author_probF'] = \\\n",
    "    1 - df_last2.loc[df_last2['Last_Author_gend'] == 'male','Last_Author_probF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbac6ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Probability female on top 30 first authors', df_first2.loc[0:30,'First_Author_probF'].sum()/30) # last index is not included!!\n",
    "print('Probability female on top 10 first authors', df_first2.loc[0:10,'First_Author_probF'].sum()/10)\n",
    "print(\"\\n\")\n",
    "# NOTE. Xin Liu is misclassified. I think is a postdoc in stanford, and he's a guy\n",
    "# there is another Xin Liu in seismology in China, another man. Their articles appear combined, as their names are identical.\n",
    "print('Probability female on top 10 first authors when binary gender', df_first2.loc[0:10,'First_Author_probF'].round().sum()/10)\n",
    "print('Probability female on top 20 first authors when binary gender', df_first2.loc[0:20,'First_Author_probF'].round().sum()/20)\n",
    "print('Probability female on top 30 first authors when binary gender', df_first2.loc[0:30,'First_Author_probF'].round().sum()/30)\n",
    "print('Probability female on top 40 first authors when binary gender', df_first2.loc[0:40,'First_Author_probF'].round().sum()/40)\n",
    "print('Probability female on top 50 first authors when binary gender', df_first2.loc[0:50,'First_Author_probF'].round().sum()/50)\n",
    "print('Probability female on top 100 first authors when binary gender', df_first2.loc[0:100,'First_Author_probF'].round().sum()/100)\n",
    "print('Probability female on top 1000 first authors when binary gender', df_first2.loc[0:1000,'First_Author_probF'].round().sum()/1000)\n",
    "print('Probability female on top 2000 first authors when binary gender', df_first2.loc[0:2000,'First_Author_probF'].round().sum()/2000)\n",
    "print('Probability female on top 10000 first authors when binary gender', df_first2.loc[0:10000,'First_Author_probF'].round().sum()/10000)\n",
    "# df_first2.iloc[0:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7613ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_f_in_n = []\n",
    "prob_m_in_n = []\n",
    "as_per_n = []\n",
    "ns = []\n",
    "plt.figure(figsize=(7.5, 4))\n",
    "# ns = np.arange(50, 5000, 10)\n",
    "\n",
    "# drop rows where the gender probability is exactly 0.5 for this case\n",
    "df_first2 = df_first2[df_first2[\"First_Author_gend\"] != \"init\"].reset_index(drop=True)\n",
    "\n",
    "p_all_female_first = len(np.where(df_first2.First_Author_probF > 0.5)[0]) / len(df_first2)\n",
    "p_all_female_first_proba = df_first2.First_Author_probF.mean()\n",
    "p_all_male_first = len(np.where(df_first2.First_Author_probF < 0.5)[0]) / len(df_first2)\n",
    "p_all_male_first_proba = (1. - df_first2.First_Author_probF).mean()\n",
    "\n",
    "print(p_all_female_first, p_all_female_first_proba, p_all_male_first, p_all_male_first_proba)\n",
    "\n",
    "# one-by-one:\n",
    "# n = df_first2.Num_papers.max()\n",
    "# while n > 0: # df_first.Num_papers.max():\n",
    "#     df_part = df_first2[df_first2.Num_papers == n]\n",
    "#     prob_f_in_n.append(df_part['First_Author_probF'].round().mean())\n",
    "#     prob_m_in_n.append((1. - df_part['First_Author_probF']).round().mean())\n",
    "#     as_per_n.append(len(df_part))\n",
    "#     ns.append(n)\n",
    "#     n -= 1\n",
    "\n",
    "# in larger bins:\n",
    "n = 25 #df_first2.Num_papers.max()\n",
    "binstep = 5\n",
    "while n >= binstep: # df_first.Num_papers.max():\n",
    "    df_part = df_first2[df_first2.Num_papers > (n- binstep)]\n",
    "    df_part = df_part[df_part[\"First_Author_probF\"] != 0.5].reset_index(drop=True)\n",
    "    df_part = df_part[df_part.Num_papers <= n]\n",
    "    prob_f_in_n.append(df_part['First_Author_probF'].round().mean())\n",
    "    prob_m_in_n.append((1. - df_part['First_Author_probF']).round().mean())\n",
    "    as_per_n.append(len(df_part))\n",
    "    ns.append(n)\n",
    "    n -= binstep\n",
    "\n",
    "plt.bar(ns, np.array(prob_m_in_n) / (np.array(prob_f_in_n) + np.array(prob_m_in_n)), width=2, color=\"darkorange\")\n",
    "plt.bar(ns, np.array(prob_f_in_n) / (np.array(prob_f_in_n) + np.array(prob_m_in_n)), width=2, color=\"rebeccapurple\")\n",
    "plt.ylabel(\"Frequency of female first authors\\n per authors with N papers\")\n",
    "plt.xlabel(\"Number of first-author papers N, by M authors each\")\n",
    "plt.title(\"Highly productive first authors are more commonly male\")\n",
    "plt.grid()\n",
    "plt.xticks(ns,\n",
    "           [\"{}<N<={}\\nM={}\".format(ns[i]-binstep, ns[i], as_per_n[i]) for i in range(len(ns))])\n",
    "plt.plot(ns, np.ones(len(ns)) * p_all_male_first, \":\", color=\"0.6\",)\n",
    "plt.plot(ns, np.ones(len(ns)) * p_all_female_first, \".-\", color=\"0.6\",)\n",
    "plt.savefig(\"most_productive_first_binned_{}.png\".format(binstep), dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# probabilistically:\n",
    "prob_f_in_n = []\n",
    "prob_m_in_n = []\n",
    "as_per_n = []\n",
    "ns = []\n",
    "plt.figure(figsize=(9, 4))\n",
    "# in larger bins:\n",
    "n = 25 #df_first2.Num_papers.max()\n",
    "binstep = 5\n",
    "while n >= binstep: # df_first.Num_papers.max():\n",
    "    df_part = df_first2[df_first2.Num_papers > (n - binstep)]\n",
    "    df_part = df_part[df_part.Num_papers <= n]\n",
    "    prob_f_in_n.append(df_part['First_Author_probF'].mean())\n",
    "    prob_m_in_n.append((1. - df_part['First_Author_probF']).mean())\n",
    "    as_per_n.append(len(df_part))\n",
    "    ns.append(n)\n",
    "    n -= binstep\n",
    "print([prob_f_in_n[ii] + prob_m_in_n[ii] for ii in range(len(prob_f_in_n))])\n",
    "#plt.plot(ns, np.array(prob_m_in_n) + np.array(prob_f_in_n))#, width=2.5)\n",
    "\n",
    "plt.bar(ns, np.array(prob_m_in_n), width=2.6, color=\"darkorange\")\n",
    "plt.bar(ns, np.array(prob_f_in_n), width=2.6, color=\"rebeccapurple\")\n",
    "plt.ylabel(\"Probability of first author gender\")\n",
    "plt.xlabel(\"Number of first-author papers N, by M authors each\")\n",
    "plt.title(\"Highly productive first authors are more commonly male\")\n",
    "plt.grid()\n",
    "plt.xticks(ns,\n",
    "           [\"{}<N<={}\\nM={}\".format(ns[i]-binstep, ns[i], as_per_n[i]) for i in range(len(ns))])\n",
    "plt.plot(ns, np.ones(len(ns)) * p_all_male_first_proba, \":\", color=\"0.6\",)\n",
    "plt.plot(ns, np.ones(len(ns)) * p_all_female_first_proba, \".-\", color=\"0.6\",)\n",
    "plt.legend([ \"P(male, all)\", \"P(female, all)\", \"P(male, bin)\", \"P(female, bin)\",], loc=5)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, 38)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"most_productive_first_binned_{}_proba.png\".format(binstep), dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d58bdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Probability female on top 30 last authors', df_last2.loc[0:29,'Last_Author_probF'].sum()/30)\n",
    "print('Probability female on top 10 last authors', df_last2.loc[0:9,'Last_Author_probF'].sum()/10)\n",
    "\n",
    "\n",
    "df_last2.iloc[0:50,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a269223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_f_in_n = []\n",
    "# prob_m_in_n = []\n",
    "# ns = np.arange(50, 7000, 10)\n",
    "# ps_per_a = []\n",
    "# n_before = 0\n",
    "\n",
    "# # drop rows where the gender probability is exactly 0.5 for this case\n",
    "# print(len(df_last2))\n",
    "# df_last2 = df_last2[df_last2[\"Last_Author_probF\"] != 0.5].reset_index(drop=True)\n",
    "# print(len(df_last2))\n",
    "\n",
    "# for n in ns:\n",
    "#     prob_f_in_n.append(df_last2.loc[0:n,'Last_Author_probF'].round().sum()/n)\n",
    "#     prob_m_in_n.append((1. - df_last2.loc[0:n,'Last_Author_probF']).round().sum()/n)\n",
    "#     ps_per_a.append(df_last2.loc[n,'Num_papers'])\n",
    "#     n_before = n\n",
    "# plt.plot(ns, prob_f_in_n)\n",
    "# plt.plot(ns, prob_m_in_n)\n",
    "# plt.ylabel(\"Frequency of gender of last author\\n out of N most productive authors\")\n",
    "# plt.xlabel(\"Nr of last-authored papers\")\n",
    "# plt.legend([\"Female\", \"Male\"])\n",
    "# plt.title(\"Senior authors are more commonly male\")\n",
    "# plt.grid()\n",
    "# plt.xticks([50, 1050, 2050, 3050, 4050],\n",
    "#            [ps_per_a[0], ps_per_a[100], ps_per_a[200],\n",
    "#             ps_per_a[300], ps_per_a[400]])\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(ns, np.array(prob_f_in_n) / (np.array(prob_f_in_n) + np.array(prob_m_in_n)))\n",
    "# plt.ylabel(\"Frequency of female last authors\\n among N most productive last authors\")\n",
    "# plt.xlabel(\"The N most productive authors with M papers each\")\n",
    "# #plt.legend([\"Female\", \"Male\"])\n",
    "# plt.title(\"Senior authors are more commonly male\")\n",
    "# plt.grid()\n",
    "# plt.xticks([50, 1050, 2050, 3050, 4050, 5050 , 6050],\n",
    "#            [\"N={}\\nM={}\".format(50, ps_per_a[0]),\n",
    "#             \"N={}\\nM={}\".format(1050, ps_per_a[100]),\n",
    "#             \"N={}\\nM={}\".format(2050, ps_per_a[200]),\n",
    "#             \"N={}\\nM={}\".format(3050, ps_per_a[300]),\n",
    "#             \"N={}\\nM={}\".format(4050, ps_per_a[400]),\n",
    "#             \"N={}\\nM={}\".format(5050, ps_per_a[500]),\n",
    "#             \"N={}\\nM={}\".format(6050, ps_per_a[600]),\n",
    "#             ])\n",
    "# plt.savefig(\"most_productive_last.png\", dpi=300)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "prob_f_in_n = []\n",
    "prob_m_in_n = []\n",
    "as_per_n = []\n",
    "ns = []\n",
    "plt.figure(figsize=(7.5, 4))\n",
    "# ns = np.arange(50, 5000, 10)\n",
    "\n",
    "# drop rows where the gender probability is exactly 0.5 for this case\n",
    "print(len(df_last2))\n",
    "print(len(df_last2))\n",
    "df_last2 = df_last2[df_last2[\"Last_Author_gend\"] != \"init\"].reset_index(drop=True)\n",
    "\n",
    "p_all_female_last = len(np.where(df_last2.Last_Author_probF > 0.5)[0]) / len(df_last2)\n",
    "p_all_male_last = len(np.where(df_last2.Last_Author_probF < 0.5)[0]) / len(df_last2)\n",
    "p_all_female_last_proba = df_last2.Last_Author_probF.mean()\n",
    "p_all_male_last_proba = (1. - df_last2.Last_Author_probF).mean()\n",
    "\n",
    "# one-by-one\n",
    "# n = 1 #df_first2.Num_papers.max()\n",
    "# while n < df_first.Num_papers.max():\n",
    "#     df_part = df_last2[df_last2.Num_papers == n]\n",
    "#     prob_f_in_n.append(df_part['Last_Author_probF'].round().mean())\n",
    "#     prob_m_in_n.append((1. - df_part['Last_Author_probF']).round().mean())\n",
    "#     as_per_n.append(len(df_part))\n",
    "#     ns.append(n)\n",
    "#     n += 1\n",
    "    \n",
    "n = 25 #df_last2.Num_papers.max()\n",
    "print(n)\n",
    "binstep = 5\n",
    "while n >= binstep: # df_first.Num_papers.max():\n",
    "    df_part = df_last2[df_last2.Num_papers > (n- binstep)]\n",
    "    df_part = df_part[df_part[\"Last_Author_probF\"] != 0.5].reset_index(drop=True)\n",
    "\n",
    "    df_part = df_part[df_part.Num_papers <= n]\n",
    "    prob_f_in_n.append(df_part['Last_Author_probF'].round().mean())\n",
    "    prob_m_in_n.append((1. - df_part['Last_Author_probF']).round().mean())\n",
    "    as_per_n.append(len(df_part))\n",
    "    ns.append(n)\n",
    "    n -= binstep\n",
    "print(ns)\n",
    "print(prob_f_in_n)\n",
    "plt.bar(ns[::-1],np.array(prob_m_in_n) / (np.array(prob_f_in_n) + np.array(prob_m_in_n)) )\n",
    "plt.bar(ns[::-1], np.array(prob_f_in_n) / (np.array(prob_f_in_n) + np.array(prob_m_in_n)))\n",
    "plt.ylabel(\"Frequency of female last authors\\n per authors with N papers\")\n",
    "plt.xlabel(\"Number of last-author papers N, by M authors each\")\n",
    "# plt.title(\"Highly productive first authors are more commonly male\")\n",
    "plt.grid()\n",
    "plt.xticks(ns[::-1],\n",
    "           [\"N={}\\nM={}\".format(ns[i], as_per_n[i]) for i in range(len(ns))])\n",
    "#plt.savefig(\"most_productive_first.png\", dpi=300)\n",
    "plt.plot(ns, np.ones(len(ns)) * p_all_female_last, \"k--\")\n",
    "plt.plot(ns, np.ones(len(ns)) * p_all_male_last, \"k--\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# probabilistically:\n",
    "prob_f_in_n = []\n",
    "prob_m_in_n = []\n",
    "as_per_n = []\n",
    "ns = []\n",
    "plt.figure(figsize=(9, 4))\n",
    "# in larger bins:\n",
    "n = 25 #df_first2.Num_papers.max()\n",
    "binstep = 5\n",
    "while n >= binstep: # df_first.Num_papers.max():\n",
    "    df_part = df_last2[df_last2.Num_papers > (n - binstep)]\n",
    "    df_part = df_part[df_part.Num_papers <= n]\n",
    "    prob_f_in_n.append(df_part['Last_Author_probF'].mean())\n",
    "    prob_m_in_n.append((1. - df_part['Last_Author_probF']).mean())\n",
    "    as_per_n.append(len(df_part))\n",
    "    ns.append(n)\n",
    "    n -= binstep\n",
    "print([prob_f_in_n[ii] + prob_m_in_n[ii] for ii in range(len(prob_f_in_n))])\n",
    "#plt.plot(ns, np.array(prob_m_in_n) + np.array(prob_f_in_n))#, width=2.5)\n",
    "plt.bar(ns, np.array(prob_m_in_n), width=2.6, color=\"darkorange\")\n",
    "plt.bar(ns, np.array(prob_f_in_n), width=2.6, color=\"rebeccapurple\")\n",
    "plt.ylabel(\"Probability of last author gender\")\n",
    "plt.xlabel(\"Number of last-author papers N, by M authors each\")\n",
    "plt.title(\"Highly productive last authors are more commonly male\")\n",
    "plt.grid()\n",
    "plt.xticks(ns,\n",
    "           [\"{}<N<={}\\nM={}\".format(ns[i]-binstep, ns[i], as_per_n[i]) for i in range(len(ns))])\n",
    "plt.plot(ns, np.ones(len(ns)) * p_all_male_last_proba, \":\", color=\"0.6\",)\n",
    "plt.plot(ns, np.ones(len(ns)) * p_all_female_last_proba, \".-\", color=\"0.6\",)\n",
    "plt.legend([ \"P(male, all)\", \"P(female, all)\", \"P(male, bin)\", \"P(female, bin)\",], loc=5)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, 38)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"most_productive_last_binned_{}_proba.png\".format(binstep), dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9669a710",
   "metadata": {},
   "source": [
    "## is it a time lag effect?\n",
    "If women only started to increase in numbers recently, this could have an effect on their overall number of publications since they had \"less time\" to accumulate them. \n",
    "\n",
    "We could check this by plotting similar graphs to above but sorted by year, I guess?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1650fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do this we must recreate the above author-ranking after year selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17418d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#years = np.arange(2010, 2021, 1)\n",
    "years = [[2010,2015], [2016, 2020]]\n",
    "f1 = plt.figure(figsize=(12, 6))\n",
    "ax1 = plt.subplot(111)\n",
    "leg1 = []\n",
    "\n",
    "import matplotlib as mpl\n",
    "import cycler\n",
    "n = 11\n",
    "color = plt.cm.Spectral(np.linspace(0, 1, n))\n",
    "mpl.rcParams['axes.prop_cycle'] = cycler.cycler('color', color)\n",
    "\n",
    "for yearbin in years:\n",
    "\n",
    "    print(condi)\n",
    "    ### Count number of papers for each author and create dictionary\n",
    "    dict_last = df[df.year in np.an[str(y) for y in yearbin]].Last_Author_clean.value_counts().to_dict()\n",
    "    dict_first = df[df.year in [str(y) for y in yearbin]].First_Author_clean.value_counts().to_dict()\n",
    "    ### Create new dataframes, one for first authors and another one for last authors\n",
    "\n",
    "    df_first_yr = df[['First_Author_clean','First_Author_gend','First_Author_gendprob', 'year']].copy()\n",
    "    df_first_yr = df_first_yr[df_first_yr.year in [str(y) for y in yearbin]]\n",
    "    df_last_yr = df[['Last_Author_clean','Last_Author_gend','Last_Author_gendprob', 'year']].copy()\n",
    "    df_last_yr = df_last_yr[df_last_yr.year in [str(y) for y in yearbin]]\n",
    "\n",
    "    df_first_yr['Num_papers'] = df_first_yr.First_Author_clean.map(dict_first) # create new column with number of papers\n",
    "    df_last_yr['Num_papers'] = df_last_yr.Last_Author_clean.map(dict_last)\n",
    "    \n",
    "    \n",
    "    ### Drop duplicated name and sort in descending order of num_papers\n",
    "    df_first_yr = df_first_yr.drop_duplicates('First_Author_clean').sort_values(by=['Num_papers'],ascending=False).reset_index(drop = True)\n",
    "    df_last_yr = df_last_yr.drop_duplicates('Last_Author_clean').sort_values(by=['Num_papers'],ascending=False).reset_index(drop = True)\n",
    "\n",
    "    \n",
    "    # drop the nans:\n",
    "    df_first_yr = df_first_yr.dropna().reset_index(drop=True)\n",
    "    df_last_yr = df_last_yr.dropna().reset_index(drop=True)\n",
    "    # Prob first author female:\n",
    "\n",
    "    df_first_yr['First_Author_probF'] = df_first_yr['First_Author_gendprob']\n",
    "    df_first_yr.loc[df_first_yr['First_Author_gend'] == 'male','First_Author_probF'] = \\\n",
    "        1 - df_first_yr.loc[df_first_yr['First_Author_gend'] == 'male','First_Author_probF']\n",
    "\n",
    "    # Prob last author female:\n",
    "    df_last_yr['Last_Author_probF'] = df_last_yr['Last_Author_gendprob']\n",
    "    df_last_yr.loc[df_last_yr['Last_Author_gend'] == 'male','Last_Author_probF'] = \\\n",
    "        1 - df_last_yr.loc[df_last_yr['Last_Author_gend'] == 'male','Last_Author_probF']\n",
    "    print(year)\n",
    "    # display(df_first_yr[0:1])\n",
    "    # display(df_last_yr[0:1])\n",
    "    \n",
    "    prob_f_in_n = []\n",
    "    prob_m_in_n = []\n",
    "    ns = []\n",
    "    as_per_n = []\n",
    "    # drop rows where the gender probability is exactly 0.5 for this case\n",
    "    #df_last_yr = df_last_yr[df_last_yr[\"Last_Author_probF\"] != 0.5].reset_index(drop=True)\n",
    "    #df_last_yr = df_last_yr[df_last_yr[\"Last_Author_gend\"] != \"init\"].reset_index(drop=True)\n",
    "\n",
    "    n = 6 #df_last_yr.Num_papers.max()\n",
    "    binstep=1\n",
    "    while n > binstep: # df_first.Num_papers.max():\n",
    "        df_part = df_last_yr[df_last_yr.Num_papers <= n]\n",
    "        df_part = df_last_yr[df_last_yr.Num_papers > n - binstep]\n",
    "        \n",
    "        if len(df_part) > 0:\n",
    "            prob_f_in_n.append(df_part['Last_Author_probF'].mean())\n",
    "            prob_m_in_n.append((1. - df_part['Last_Author_probF']).mean())\n",
    "            as_per_n.append(len(df_part))\n",
    "            ns.append(n)\n",
    "        n -= binstep\n",
    "    print(ns)\n",
    "    ax1.plot(ns, np.array(prob_f_in_n), \"d\", markersize=20, alpha=0.5)\n",
    "    leg1.append(\"{}-{}, n={}\".format(yearbin[0], yearbin[1], len(df_last_yr)))\n",
    "    \n",
    "    prob_f_in_n = []\n",
    "    \n",
    "ax1.legend(leg1, loc=0, ncol=2)\n",
    "plt.xticks(ns, [\"{}<N<={}\\nM={}\".format(ns[i]-binstep, ns[i], as_per_n[i]) for i in range(len(ns))])\n",
    "ax1.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df4aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(2010, 2021, 1)\n",
    "f1 = plt.figure(figsize=(12, 6))\n",
    "ax1 = plt.subplot(111)\n",
    "f2 = plt.figure(figsize=(12, 6))\n",
    "ax2 = plt.subplot(111)\n",
    "leg2 = []\n",
    "leg1 = []\n",
    "\n",
    "import matplotlib as mpl\n",
    "import cycler\n",
    "n = 11\n",
    "color = plt.cm.Spectral(np.linspace(0, 1, n))\n",
    "mpl.rcParams['axes.prop_cycle'] = cycler.cycler('color', color)\n",
    "\n",
    "for year in years:\n",
    "    ### Count number of papers for each author and create dictionary\n",
    "    dict_last = df[df.year==str(year)].Last_Author_clean.value_counts().to_dict()\n",
    "    dict_first = df[df.year==str(year)].First_Author_clean.value_counts().to_dict()\n",
    "    ### Create new dataframes, one for first authors and another one for last authors\n",
    "\n",
    "    df_first_yr = df[['First_Author_clean','First_Author_gend','First_Author_gendprob', 'year']].copy()\n",
    "    df_first_yr = df_first_yr[df_first_yr.year == str(year)]\n",
    "    df_last_yr = df[['Last_Author_clean','Last_Author_gend','Last_Author_gendprob', 'year']].copy()\n",
    "    df_last_yr = df_last_yr[df_last_yr.year == str(year)]\n",
    "\n",
    "    df_first_yr['Num_papers'] = df_first_yr.First_Author_clean.map(dict_first) # create new column with number of papers\n",
    "    df_last_yr['Num_papers'] = df_last_yr.Last_Author_clean.map(dict_last)\n",
    "    \n",
    "    \n",
    "    ### Drop duplicated name and sort in descending order of num_papers\n",
    "    df_first_yr = df_first_yr.drop_duplicates('First_Author_clean').sort_values(by=['Num_papers'],ascending=False).reset_index(drop = True)\n",
    "    df_last_yr = df_last_yr.drop_duplicates('Last_Author_clean').sort_values(by=['Num_papers'],ascending=False).reset_index(drop = True)\n",
    "\n",
    "    \n",
    "    # drop the nans:\n",
    "    df_first_yr = df_first_yr.dropna().reset_index(drop=True)\n",
    "    df_last_yr = df_last_yr.dropna().reset_index(drop=True)\n",
    "    # Prob first author female:\n",
    "\n",
    "    df_first_yr['First_Author_probF'] = df_first_yr['First_Author_gendprob']\n",
    "    df_first_yr.loc[df_first_yr['First_Author_gend'] == 'male','First_Author_probF'] = \\\n",
    "        1 - df_first_yr.loc[df_first_yr['First_Author_gend'] == 'male','First_Author_probF']\n",
    "\n",
    "    # Prob last author female:\n",
    "    df_last_yr['Last_Author_probF'] = df_last_yr['Last_Author_gendprob']\n",
    "    df_last_yr.loc[df_last_yr['Last_Author_gend'] == 'male','Last_Author_probF'] = \\\n",
    "        1 - df_last_yr.loc[df_last_yr['Last_Author_gend'] == 'male','Last_Author_probF']\n",
    "    print(year)\n",
    "    # display(df_first_yr[0:1])\n",
    "    # display(df_last_yr[0:1])\n",
    "    \n",
    "    prob_f_in_n = []\n",
    "    prob_m_in_n = []\n",
    "    ns = []\n",
    "    as_per_n = []\n",
    "    n_before = 0\n",
    "\n",
    "    # drop rows where the gender probability is exactly 0.5 for this case\n",
    "    df_last_yr = df_last_yr[df_last_yr[\"Last_Author_probF\"] != 0.5].reset_index(drop=True)\n",
    "    df_last_yr = df_last_yr[df_last_yr[\"Last_Author_gend\"] != \"init\"].reset_index(drop=True)\n",
    "\n",
    "    n = 10 #df_last_yr.Num_papers.max()\n",
    "    while n > 0: # df_first.Num_papers.max():\n",
    "        df_part = df_last_yr[df_last_yr.Num_papers == n]\n",
    "        \n",
    "        if len(df_part) > 0:\n",
    "            prob_f_in_n.append(df_part['Last_Author_probF'].round().mean())\n",
    "            prob_m_in_n.append((1. - df_part['Last_Author_probF']).round().mean())\n",
    "            as_per_n.append(len(df_part))\n",
    "            ns.append(n)\n",
    "        n -= 1\n",
    "    print(ns)\n",
    "    ax1.plot(ns, np.array(prob_f_in_n) / (np.array(prob_f_in_n) + np.array(prob_m_in_n)), \"d\",markersize=20, alpha=0.5)\n",
    "    leg1.append(\"{}, n={}\".format(year, len(df_last_yr)))\n",
    "    \n",
    "    prob_f_in_n = []\n",
    "    prob_m_in_n = []\n",
    "    ns = []\n",
    "    as_per_n = []\n",
    "    n_before = 0\n",
    "\n",
    "    # drop rows where the gender probability is exactly 0.5 for this case\n",
    "    df_first_yr = df_first_yr[df_first_yr[\"First_Author_probF\"] != 0.5].reset_index(drop=True)\n",
    "    df_first_yr = df_first_yr[df_first_yr[\"First_Author_gend\"] != \"init\"].reset_index(drop=True)\n",
    "\n",
    "    n = df_first_yr.Num_papers.max()\n",
    "    while n > 0: # df_first.Num_papers.max():\n",
    "        df_part = df_first_yr[df_first_yr.Num_papers == n]\n",
    "        \n",
    "        if len(df_part) > 0:\n",
    "            prob_f_in_n.append(df_part['First_Author_probF'].round().mean())\n",
    "            prob_m_in_n.append((1. - df_part['First_Author_probF']).round().mean())\n",
    "            as_per_n.append(len(df_part))\n",
    "            ns.append(n)\n",
    "        n -= 1\n",
    "    print(ns)\n",
    "    ax2.plot(ns, np.array(prob_f_in_n) / (np.array(prob_f_in_n) + np.array(prob_m_in_n)), \"d\",markersize=20, alpha=0.5)\n",
    "    leg2.append(\"{}, n={}\".format(year, len(df_last_yr)))\n",
    "    \n",
    "ax1.legend(leg1, loc=5, ncol=2)\n",
    "plt.gca()\n",
    "plt.xticks(np.arange(len(ns)) + 1,\n",
    "           [\"N={}\\nM={}\".format(ns[i], as_per_n[i]) for i in range(len(ns))])\n",
    "ax2.legend(leg2, loc=5, ncol=2)\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "picos",
   "language": "python",
   "name": "picos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
