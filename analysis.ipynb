{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook looks at a lot of basic statistics of our dataset.\n",
    "\n",
    "It includes:\n",
    "- overall probability of female / male first authorship (0.2767 / 0.7233)\n",
    "- overall probability of female / male last authorship (0.1908 / 0.8092)\n",
    "- overall probability of female / male authorship in any position (0.2347 / 0.7653)\n",
    "\n",
    "Next, it checks how high the probability is to have at least 1 female author depending on the overall occurrence of female authors and the number of authors per paper, using the formula that having all male authors of one paper is Pmale^nr.authors. Compared to this \"random draw\" expectation, it formulates a bias when the data donot agree with this random draw. This reveals:\n",
    "- Men are overrepresented as single authors\n",
    "- From the pure theory of probability and the average rate of male / female representation, it is very unlikely to have an all-female authorship team, whereas it is very common to have an all-male authorship team. collaboration\n",
    "- there appears to be a slight gender segregation effect, i.e. men tend to publish in all-male authorship groups (here I still do not understand what is going on). This result needs more thinking and double-checking.\n",
    "\n",
    "We then test this comparison of random draw vs. data when it comes to having at least one female / male author per publication, separated by journal. the main results are:\n",
    "- the under-representation of women as single-authors applies to all investigated journals \n",
    "- Geophysics has markedly lower representation of women authors than all other journals\n",
    "\n",
    "Next, we explore the prob. of male / female authorship per year. \n",
    "- we find an increase rate around 0.3 % per year. Simply waiting for parity would take a long time.\n",
    "\n",
    "Finally, there are synthetics to check the at-least-one-per-n probability. I think these are also in the notebook analysis-Synthetics now, and are as a sort of backup here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the follwoing packages in the enviroment:\n",
    "# python3 -m pip install pandas\n",
    "# python3 -m pip install seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import os\n",
    "\n",
    "from read_jsondata import read_jsons\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypotheses to be tested\n",
    "\n",
    "#### As reference values to compare to, we will use demographics from ECS from AGU and EGU. This will give an idea of how many of the active scientists at these professional levels are represented to the peer-reviewed articles (which is the main crucial factor for career advancing and perhaps the daily goal of most academics)\n",
    "\n",
    "FIRST GLANCES AT DATA\n",
    "\n",
    "- % of female first authors (hists?)\n",
    "- % publications with all male vs. % publications with all female authors (hists?)\n",
    "\n",
    "CO-AUTHORSHIP ANALYSES\n",
    "\n",
    "- When 1st author is female: % of male vs. female co-authors (bars..?)\n",
    "- When 1st author is female: likelihood of last author (possibly PI) to be female vs. male \n",
    "- When 1st author is male: % of female coauthors and % of male coauthors\n",
    "- When the last name is female (possible PI), is there a higher % of female co-authors vs. male ones?\n",
    "\n",
    "JOURNAL IF ANALYSES:\n",
    "\n",
    "- Correlation between IF and female first authors: does higher IF mean fewer female first authors?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define local paths\n",
    "\n",
    "root = ! pwd\n",
    "root = root[0]\n",
    "\n",
    "RAW_DIR=root+\"/author_allgenders/\"  \n",
    "\n",
    "if not os.path.exists(RAW_DIR):\n",
    "    print(\"The directory {} does not exist.\\nThere is no raw data for statistical analysis.\".format(RAW_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_jsons(RAW_DIR)  # included here cleanup and IF and removing 2021\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new columns in the dataframe extracting useful information from list of coauthors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of authors:\n",
    "\n",
    "df['Number_authors'] = df['all_genders'].apply(lambda x: len(x)) #take the length of the list all_genders\n",
    "df['Number_init'] = df['all_genders'].apply(lambda x: len([s for s in x if \"init\"==s]))\n",
    "\n",
    "\n",
    "# First author's gender and percentage:\n",
    "\n",
    "df['First_Author_gend'] = df['all_genders'].apply(lambda x: x[0]) #take the first element of the list all_genders\n",
    "df['First_Author_perc'] = df['all_percent'].apply(lambda x: x[0])\n",
    "\n",
    "# Last author's gender and percentage:\n",
    "\n",
    "df['Last_Author_gend'] = df['all_genders'].apply(lambda x: x[-1]) #take the last element of the list all_genders\n",
    "df['Last_Author_perc'] = df['all_percent'].apply(lambda x: x[-1])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropping init (unidentified initialed names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Number_init==0].copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### It is easier if the all probabilities are with respect to the same gender (female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob(female) = 1 - prob(male)\n",
    "\n",
    "# Prob last author female:\n",
    "\n",
    "df['Last_Author_probF'] = df['Last_Author_perc']\n",
    "df.loc[df['Last_Author_gend'] == 'male','Last_Author_probF'] = \\\n",
    "    1 - df.loc[df['Last_Author_gend'] == 'male','Last_Author_probF']\n",
    "\n",
    "# Prob first author female:\n",
    "\n",
    "df['First_Author_probF'] = df['First_Author_perc']\n",
    "df.loc[df['First_Author_gend'] == 'male','First_Author_probF'] = \\\n",
    "    1 - df.loc[df['First_Author_gend'] == 'male','First_Author_probF']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can compute some interesting probabilities:\n",
    "\n",
    "### Useful formulas:\n",
    "\n",
    "Suppose $x_i$ refers to the article $i$ and $N$ is the total number of articles. Then, the probability of an article having female author is:\n",
    "\n",
    "$$p(\\text{female}) = \\sum_{i}^N p(\\text{female}|x_i) p(x_i). $$\n",
    "\n",
    "If we have all the probabilities with respect to the female gender, then the probability of having a male author will be:\n",
    "\n",
    "$$p(\\text{male}) = \\sum_{i}^N (1 - p(\\text{female}|x_i)) p(x_i). $$\n",
    "\n",
    "$p(x_i)$ is the probability of the article $x_i$. All articles have the same probability, therefore $p(x_i) = \\frac{1}{N}$. This means that the formulas above are same as taking the average of  $p(\\text{female}|x_i)$ or $(1 - p(\\text{female}|x_i))$, respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compute some easy statistics to start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Probability of having a female first author:', df['First_Author_probF'].sum()/df.shape[0])\n",
    "print('Probability of having a male first author:', (1 - df['First_Author_probF']).sum()/df.shape[0])\n",
    "\n",
    "print('Probability of having a female last author:', df['Last_Author_probF'].sum()/df.shape[0])\n",
    "print('Probability of having a male last author:', (1 - df['Last_Author_probF']).sum()/df.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prob_author(x,y, kind=\"female\", allkinds=\"malefemale\"):\n",
    "    sum = 0\n",
    "    for i,elem in enumerate(x):\n",
    "        if elem not in allkinds:\n",
    "            continue\n",
    "        if elem != kind:\n",
    "            sum += 1 - float(y[i]) \n",
    "        elif elem == kind:\n",
    "            sum += float(y[i])\n",
    "    return sum\n",
    "\n",
    "def count_kind(x, kind=\"init\"):\n",
    "    sum = 0\n",
    "    for elem in x:\n",
    "        if elem == kind:\n",
    "            sum += 1\n",
    "    return(sum)\n",
    "\n",
    "# 1) determine overall frequencies\n",
    "#==================================\n",
    "# How many authors in total?\n",
    "n_authors_all =df.Number_authors.sum()\n",
    "n_authors_all\n",
    "# Sum of probability of female / total nr. \n",
    "p_female_all = df.apply(lambda x: Prob_author(x.all_genders, x.all_percent, kind=\"female\"), axis=1).sum() / n_authors_all\n",
    "\n",
    "# Sum of probability of male / total nr.\n",
    "p_male_all = df.apply(lambda x: Prob_author(x.all_genders, x.all_percent, kind=\"male\"), axis=1).sum() / n_authors_all\n",
    "\n",
    "# Sum of init / total nr\n",
    "p_init_all =  df.apply(lambda x: count_kind(x.all_genders), axis=1).sum() / n_authors_all\n",
    "#==================================\n",
    "\n",
    "\n",
    "\n",
    "# Now print some info; Check it adds to 1\n",
    "#==================================\n",
    "print(\"All probabilities sum: \", p_female_all + p_male_all + p_init_all)\n",
    "print(\"Overall P of female authorship: \", p_female_all)\n",
    "print(\"Overall P of male authorship: \", p_male_all)\n",
    "print(\"Overall P of unidentified names: \",p_init_all)\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# correct for init values\n",
    "n_init = df.apply(lambda x: count_kind(x.all_genders), axis=1).sum()\n",
    "# Sum of probability of female / total nr. \n",
    "p_female_all = df.apply(lambda x: Prob_author(x.all_genders, x.all_percent, kind=\"female\"), axis=1).sum() / (n_authors_all - n_init)\n",
    "\n",
    "# Sum of probability of male / total nr.\n",
    "p_male_all = df.apply(lambda x: Prob_author(x.all_genders, x.all_percent, kind=\"male\"), axis=1).sum() / (n_authors_all - n_init)\n",
    "print(\"All probabilities sum: \", p_female_all + p_male_all)\n",
    "print(\"Overall frequency of female authorship after accounting for init: \", 100.*p_female_all)\n",
    "print(\"Overall frequency of male authorship after accounting for init: \", 100.*p_male_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilities of having at least one male/female author in an article\n",
    "\n",
    "Having at least one female author refers to any coauthor combination excluding the case in which all authors are male:\n",
    "\n",
    "$$p(\\text{at least 1 female}|x_i) = 1 - p(\\text{all male}|x_i)$$\n",
    "\n",
    "Computing probability for all male coauthors is easier. In the following, we drop the dependency on $x_i$ for clarity.\n",
    "\n",
    "$$p(\\text{all male}) = p(\\text{male}_1)p(\\text{male}_2|\\text{male}_1)p(\\text{male}_3|\\text{male}_1,\\text{male}_2)... = \\prod_i^n p(\\text{male}_i)$$\n",
    "\n",
    "where n is the number of authors and the last step assumes that the gender probability of each authorship is independent of the gender of other coauthors (just to simplify the problem). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define functions to multiply probabilities in each row\n",
    "\n",
    "#prob at least a female author\n",
    "\n",
    "def Prob_atleast_Fauthor(x,y):\n",
    "    prod = 1\n",
    "    for i,elem in enumerate(x):\n",
    "        if elem == 'male':\n",
    "            prod *= float(y[i]) \n",
    "        elif elem == 'female':\n",
    "            prod *= 1 - float(y[i])\n",
    "    return 1 - prod\n",
    "\n",
    "#prob at least a male author\n",
    "\n",
    "def Prob_atleast_Mauthor(x,y):\n",
    "    prod = 1\n",
    "    for i,elem in enumerate(x):\n",
    "        if elem == 'male':\n",
    "            prod *= 1 - float(y[i]) \n",
    "        elif elem == 'female':\n",
    "            prod *= float(y[i])\n",
    "    return 1 - prod\n",
    "\n",
    "def Prob_atleast_bin(x,y, gender_atleast, gender_other):\n",
    "    prod = 1\n",
    "    for i,elem in enumerate(x):\n",
    "        if elem == gender_other:\n",
    "            prod *= round(y[i]) \n",
    "        elif elem == gender_atleast:\n",
    "            prod *= 1 - round(y[i])\n",
    "    return 1 - prod\n",
    "\n",
    "\n",
    "# Create corresponding columns:\n",
    "\n",
    "df['Prob_atleast_Fauthor'] = df.apply(lambda x: Prob_atleast_Fauthor(x.all_genders, x.all_percent), axis=1)\n",
    "df['Prob_atleast_Mauthor'] = df.apply(lambda x: Prob_atleast_Mauthor(x.all_genders, x.all_percent), axis=1)\n",
    "\n",
    "# add the same columns as if the authors were binary\n",
    "\n",
    "df['Prob_atleast_Fauthor_binary'] = df.apply(lambda x: Prob_atleast_bin(x.all_genders, x.all_percent, \"female\", \"male\"), axis=1)\n",
    "df['Prob_atleast_Mauthor_binary'] = df.apply(lambda x: Prob_atleast_bin(x.all_genders, x.all_percent, \"male\", \"female\"), axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Probability of having at least one female author in an article', \n",
    "      df['Prob_atleast_Fauthor'].sum()/df.shape[0])\n",
    "\n",
    "print('Probability of having at least one male author in an article', \n",
    "      df['Prob_atleast_Mauthor'].sum()/df.shape[0])\n",
    "\n",
    "print('or the opposite...')\n",
    "\n",
    "print('Probability of having all female authors in an article', \n",
    "      1 - df['Prob_atleast_Mauthor'].sum()/df.shape[0])\n",
    "\n",
    "print('Probability of having all male authors in an article', \n",
    "      1 - df['Prob_atleast_Fauthor'].sum()/df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### in between: Overall frequency of female / male authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# so if we go by these rough probabilities then...\n",
    "print(\"=\" * 100)\n",
    "print(\"Probability that a paper with x author(s) has at least 1 female author:\")\n",
    "print(\"x=1: p=\", round(1. - p_male_all, 3), \";   x=2: p=\", round(1. - p_male_all ** 2, 3),\n",
    "      \";   x=3: p=\", round(1. - p_male_all ** 3, 3), \";   p=10: p=\", round(1. - p_male_all ** 10, 3))\n",
    "print(\"=\" * 100)\n",
    "# and the reverse:\n",
    "print(\"Probability that a paper with x author(s) has only female authors:\")\n",
    "print(\"x=1: p=\", round(p_female_all, 3), \";   x=2: p=\", round(p_female_all ** 2, 3),\n",
    "      \";   x=3: p=\", round(p_female_all ** 3, 3), \";   p=10: p=\", round(p_female_all ** 10, 3))\n",
    "# etc\n",
    "print(\"=\" * 100)\n",
    "#==================================\n",
    "\n",
    "\n",
    "\n",
    "# Compute theoretical probabilities of having all male / all female / 1 male / 1 female author(s)\n",
    "#==================================\n",
    "\n",
    "n_authors = range(1, 21)\n",
    "p_one_f_given_n = 1. - p_male_all ** n_authors\n",
    "p_one_m_given_n = 1. - p_female_all ** n_authors\n",
    "\n",
    "p_all_f_given_n = p_female_all ** n_authors\n",
    "p_all_m_given_n = p_male_all ** n_authors\n",
    "\n",
    "\n",
    "# UGLY CODE below. Please fix if you are inspired\n",
    "n_authors_data = df.Number_authors.unique()\n",
    "n_authors_data.sort()\n",
    "\n",
    "p_atleast_f_per_n = []\n",
    "p_atleast_m_per_n = []\n",
    "p_all_f_per_n = []\n",
    "p_all_m_per_n = []\n",
    "p_atleast_f_per_n_binary = []\n",
    "p_atleast_m_per_n_binary = []\n",
    "p_all_f_per_n_binary = []\n",
    "p_all_m_per_n_binary = []\n",
    "\n",
    "nr_papers_n = []\n",
    "n_authors_data = n_authors_data[0: 20]\n",
    "for i in n_authors_data:\n",
    "    p_atleast_f_per_n.append(100*df[df.Number_authors == i].Prob_atleast_Fauthor.mean())    \n",
    "    p_atleast_m_per_n.append(100*df[df.Number_authors == i].Prob_atleast_Mauthor.mean())\n",
    "    p_all_f_per_n.append(100*(1. - df[df.Number_authors == i].Prob_atleast_Mauthor).mean())\n",
    "    p_all_m_per_n.append(100*(1. - df[df.Number_authors == i].Prob_atleast_Fauthor).mean())\n",
    "    \n",
    "    p_atleast_f_per_n_binary.append(100*df[df.Number_authors == i].Prob_atleast_Fauthor_binary.mean())    \n",
    "    p_atleast_m_per_n_binary.append(100*df[df.Number_authors == i].Prob_atleast_Mauthor_binary.mean())\n",
    "    p_all_f_per_n_binary.append(100*(1. - df[df.Number_authors == i].Prob_atleast_Mauthor_binary).mean())\n",
    "    p_all_m_per_n_binary.append(100*(1. - df[df.Number_authors == i].Prob_atleast_Fauthor_binary).mean())\n",
    "    \n",
    "    nr_papers_n.append(len(df[df.Number_authors == i])) \n",
    "# End ugly crap code\n",
    "#==================================\n",
    "    \n",
    "\n",
    "# plot \n",
    "#==================================\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.subplot(221)\n",
    "#plt.scatter(n_authors_data, p_atleast_f_per_n, color=\"g\", alpha=0.7)\n",
    "#plt.scatter(n_authors_data, p_atleast_f_per_n_binary, color=\"purple\", alpha=0.7)\n",
    "#plt.scatter(n_authors, 100*p_one_f_given_n, marker=\"x\")\n",
    "\n",
    "plt.bar(n_authors_data, p_atleast_f_per_n, color=\"darkblue\", alpha=0.7)\n",
    "plt.bar(n_authors_data, p_atleast_f_per_n_binary, color=\"lightskyblue\", alpha=0.7)\n",
    "plt.plot(n_authors, p_one_f_given_n*100, \"o\", color=\"0.7\", markersize=8)\n",
    "\n",
    "plt.grid()\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(0., 110)\n",
    "plt.xticks([i for i in range(0, 11, 2)], [\"\" for i in range(0, 11, 2)])\n",
    "plt.title(\"Probability at least 1 f\")\n",
    "plt.legend([\"Random draw\", \"Data\", \"Data (binary)\", ], loc=4)\n",
    "\n",
    "\n",
    "plt.subplot(222)\n",
    "# plt.scatter(n_authors_data, p_atleast_m_per_n, color=\"g\", alpha=0.7)\n",
    "# plt.scatter(n_authors_data, p_atleast_m_per_n_binary, color=\"purple\", alpha=0.7)\n",
    "# plt.scatter(n_authors, 100*p_one_m_given_n, marker=\"x\")\n",
    "\n",
    "plt.bar(n_authors_data, p_atleast_m_per_n, color=\"maroon\", alpha=0.7)\n",
    "plt.bar(n_authors_data, p_atleast_m_per_n_binary, color=\"salmon\", alpha=0.7)\n",
    "plt.plot(n_authors, p_one_m_given_n*100, \"o\", color=\"0.7\", markersize=8)\n",
    "\n",
    "plt.grid()\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(0., 110)\n",
    "plt.title(\"Probability at least 1 m\")\n",
    "plt.legend([\"Random draw\", \"Data\",\"Data (binary)\"], loc=4)\n",
    "\n",
    "plt.xticks([i for i in range(0, 11, 2)], [\"\" for i in range(0, 11, 2)])\n",
    "\n",
    "plt.subplot(223)\n",
    "# plt.scatter(n_authors_data, p_all_f_per_n, color=\"g\", alpha=0.7)\n",
    "# plt.scatter(n_authors_data, p_all_f_per_n_binary, color=\"purple\", alpha=0.7)\n",
    "# plt.scatter(n_authors, 100*p_all_f_given_n, marker=\"x\")\n",
    "plt.bar(n_authors_data, p_all_f_per_n, color=\"darkblue\", alpha=0.7)\n",
    "plt.bar(n_authors_data, p_all_f_per_n_binary, color=\"lightskyblue\", alpha=0.7)\n",
    "plt.plot(n_authors, 100*p_all_f_given_n, \"o\", color=\"0.7\", markersize=8)\n",
    "plt.grid()\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(0., 110)\n",
    "\n",
    "plt.title(\"Probability all f\")\n",
    "plt.legend([\"Random draw\", \"Data\",\"Data (binary)\",])\n",
    "\n",
    "plt.xlabel(\"Nr. of authors\")\n",
    "plt.subplot(224)\n",
    "# plt.scatter(n_authors_data, p_all_m_per_n, color=\"g\", alpha=0.7)\n",
    "# plt.scatter(n_authors_data, p_all_m_per_n_binary, color=\"purple\", alpha=0.7)\n",
    "# plt.scatter(n_authors, 100*p_all_m_given_n, marker=\"x\")\n",
    "plt.bar(n_authors_data, p_all_m_per_n, color=\"maroon\", alpha=0.7)\n",
    "plt.bar(n_authors_data, p_all_m_per_n_binary, color=\"salmon\", alpha=0.7)\n",
    "plt.plot(n_authors, 100*p_all_m_given_n, \"o\", color=\"0.7\", markersize=8)\n",
    "plt.grid()\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(0., 110)\n",
    "plt.title(\"Probability all m\")\n",
    "plt.legend([\"Random draw\", \"Data\",\"Data (binary)\", ])\n",
    "plt.xlabel(\"Nr. of authors\")\n",
    "\n",
    "plt.savefig(\"prob_atleast_all.png\", dpi=300)\n",
    "print(nr_papers_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "plt.subplot(221)\n",
    "# plt.scatter(n_authors_data,  p_atleast_f_per_n - 100*p_one_f_given_n, marker=\"x\")\n",
    "# plt.scatter(n_authors_data,  p_atleast_f_per_n_binary - 100*p_one_f_given_n, marker=\"x\")\n",
    "plt.bar(n_authors_data,  p_atleast_f_per_n_binary - 100*p_one_f_given_n,color=\"palegreen\")\n",
    "plt.bar(n_authors_data,  p_atleast_f_per_n - 100*p_one_f_given_n, color=\"darkgreen\")\n",
    "\n",
    "plt.grid()\n",
    "plt.xlim(0, 10)\n",
    "#plt.ylim(-7.5, 7.5)\n",
    "plt.ylim(-10, 10)\n",
    "\n",
    "plt.legend([\"Binary\", \"Prob.\"])\n",
    "plt.xticks([i for i in range(0, 11, 2)], [\"\" for i in range(0, 11, 2)])\n",
    "plt.title(\"Bias at least 1 f\")\n",
    "\n",
    "\n",
    "plt.subplot(222)\n",
    "# plt.scatter(n_authors_data, p_atleast_m_per_n - 100*p_one_m_given_n, marker=\"x\")\n",
    "# plt.scatter(n_authors_data, p_atleast_m_per_n_binary - 100*p_one_m_given_n, marker=\"x\")\n",
    "plt.bar(n_authors_data, p_atleast_m_per_n_binary - 100*p_one_m_given_n, color=\"palegreen\")\n",
    "plt.bar(n_authors_data, p_atleast_m_per_n - 100*p_one_m_given_n, color=\"darkgreen\")\n",
    "\n",
    "plt.grid()\n",
    "plt.xlim(0, 10)\n",
    "#plt.ylim(-7.5, 7.5)\n",
    "plt.ylim(-10, 10)\n",
    "\n",
    "plt.xticks([i for i in range(0, 11, 2)], [\"\" for i in range(0, 11, 2)])\n",
    "plt.legend([\"Binary\", \"Prob.\"])\n",
    "\n",
    "plt.title(\"Bias at least 1 m\")\n",
    "\n",
    "\n",
    "plt.subplot(223)\n",
    "#plt.scatter(n_authors_data,  p_all_f_per_n - 100*p_all_f_given_n, marker=\"x\")\n",
    "#plt.scatter(n_authors_data,  p_all_f_per_n_binary - 100*p_all_f_given_n, marker=\"x\")\n",
    "plt.bar(n_authors_data,  p_all_f_per_n_binary - 100*p_all_f_given_n, color=\"palegreen\")\n",
    "plt.bar(n_authors_data,  p_all_f_per_n - 100*p_all_f_given_n, color=\"darkgreen\")\n",
    "\n",
    "plt.grid()\n",
    "plt.xlim(0, 10)\n",
    "#plt.ylim(-7.5, 7.5)\n",
    "plt.ylim(-10, 10)\n",
    "\n",
    "plt.xticks([i for i in range(0, 11, 2)], [i for i in range(0, 11, 2)])\n",
    "plt.legend([\"Binary\", \"Prob.\"], loc=4)\n",
    "plt.xlabel(\"Nr. of authors\")\n",
    "plt.xlabel(\"Nr. of authors\")\n",
    "plt.title(\"Bias all f\")\n",
    "\n",
    "\n",
    "plt.subplot(224)\n",
    "#plt.scatter(n_authors_data, p_all_m_per_n - 100*p_all_m_given_n, marker=\"x\")\n",
    "#plt.scatter(n_authors_data, p_all_m_per_n_binary - 100*p_all_m_given_n, marker=\"x\")\n",
    "plt.bar(n_authors_data, p_all_m_per_n_binary - 100*p_all_m_given_n, color=\"palegreen\")\n",
    "plt.bar(n_authors_data, p_all_m_per_n - 100*p_all_m_given_n, color=\"darkgreen\")\n",
    "\n",
    "plt.grid()\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(-10, 10)\n",
    "plt.xticks([i for i in range(0, 11, 2)], [i for i in range(0, 11, 2)])\n",
    "plt.legend([\"Binary\", \"Prob.\"], loc=4)\n",
    "plt.xlabel(\"Nr. of authors\")\n",
    "\n",
    "plt.title(\"Bias all m\")\n",
    "plt.savefig(\"bias_with_binary.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average number of authors for articles', \n",
    "      df['Number_authors'].sum()/df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Expected probability of having at least one author in an article:', \n",
    "      1. - p_male_all ** (df['Number_authors'].sum()/df.shape[0]))\n",
    "print('Expected probability of having at least one male author in an article:', \n",
    "      1. - p_female_all ** (df['Number_authors'].sum()/df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Expected probability of having at least one author in an article with 4 authors:', \n",
    "      1. - p_male_all ** 4)\n",
    "print('Expected probability of having at least one male author in an article with 4 authors:', \n",
    "      1. - p_female_all ** 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### important: these results may be sensitive to accounting for non-gendered \"init\" data points in computing the P_atleast.... We should remove them for a cleaner result. I think we could correct for them by enforcing that p_allmale and p_onefemale must sum to one (now not the exact)\n",
    "- With the number of papers in each category, we may consider everything up to about 10 authors a decent sample size? (for n_authors=10, n_papers = 252)\n",
    "- men are overrepresented in single-author papers\n",
    "- gender mixing of authors is not random: the probability of mixed authorships in the data does not reflect a random choice based on overall gender frequencies in the data. The data show more likely all-male and all-female papers compared to random choice by overall frequency. This seems to be particularly the case for all-male author groups. Boys club?\n",
    "- this may put female authors at disavantage, because their available pool of co-authors is smaller, while men have an increased co-author pool. Female authors may be at disadvantage with regard to forging collaboration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can compute the same quantity per each journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "journals = df['journal'].unique() # a list of unique journal names\n",
    "\n",
    "df['P_atleast_F_journal'] = df['Prob_atleast_Fauthor'] #initialize the columns\n",
    "df['P_atleast_M_journal'] = df['Prob_atleast_Mauthor']\n",
    "\n",
    "for i in journals: #update values for each journal\n",
    "    cond = df['journal']==i\n",
    "    print(\"N = \", len(df[cond].values), \" for journal \", i)\n",
    "    df.loc[cond,'P_atleast_F_journal'] = df.loc[cond,'Prob_atleast_Fauthor'].sum()/df[cond].shape[0]\n",
    "    df.loc[cond,'P_atleast_M_journal'] = df.loc[cond,'Prob_atleast_Mauthor'].sum()/df[cond].shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_IF =  {'Nature': 46.486, 'Science': 41.845, 'NatureGeoscience': 16.103, 'EPSL': 4.823, 'GRL': 4.952, \n",
    "        'JGRSolidEarth': 4.191, 'G3': 3.721, 'SRL': 3.131, 'Tectp': 3.048, 'SolidEarth': 2.921, \n",
    "       'GEOPHYSICS': 3.093, 'GJI': 2.834, 'BSSA': 2.274, 'PEPI': 2.413}\n",
    "sns.barplot(y=\"journal\", x=\"P_atleast_F_journal\",  data=df, order=dict_IF.keys(), palette='rainbow').set_title('Prob of at least one female per journal')\n",
    "plt.xlim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y=\"journal\", x=\"P_atleast_M_journal\",  data=df, order=dict_IF.keys(), palette='rainbow').set_title('Prob of at least one male per journal')\n",
    "plt.xlim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can compare the probability of at least one female author given Nr. of authors for \"overall data\", \"predicted\" and \"per journal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another ugly crap code, plz help\n",
    "p_atleast_f_per_n_natnatgeo = []\n",
    "p_atleast_m_per_n_natnatgeo = []\n",
    "nr_papers_n_natnatgeo = []\n",
    "\n",
    "p_atleast_f_per_n_highIF = []\n",
    "p_atleast_m_per_n_highIF = []\n",
    "nr_papers_n_highIF = []\n",
    "\n",
    "p_atleast_f_per_n_sci = []\n",
    "nr_papers_n_sci = []\n",
    "\n",
    "p_atleast_f_per_n_jgr = []\n",
    "p_atleast_m_per_n_jgr = []\n",
    "nr_papers_n_jgr = []\n",
    "\n",
    "p_atleast_f_per_n_gji = []\n",
    "p_atleast_m_per_n_gji = []\n",
    "nr_papers_n_gji = []\n",
    "\n",
    "p_atleast_f_per_n_bssa = []\n",
    "p_atleast_m_per_n_bssa = []\n",
    "nr_papers_n_bssa = []\n",
    "\n",
    "p_atleast_f_per_n_srl = []\n",
    "p_atleast_m_per_n_srl = []\n",
    "nr_papers_n_srl = []\n",
    "\n",
    "p_atleast_f_per_n_gp = []\n",
    "p_atleast_m_per_n_gp = []\n",
    "nr_papers_n_gp = []\n",
    "\n",
    "p_atleast_f_per_n_t = []\n",
    "p_atleast_m_per_n_t = []\n",
    "nr_papers_n_t = []\n",
    "\n",
    "p_atleast_f_per_n_grl = []\n",
    "p_atleast_m_per_n_grl = []\n",
    "nr_papers_n_grl = []\n",
    "\n",
    "p_atleast_f_per_n_pepi = []\n",
    "p_atleast_m_per_n_pepi = []\n",
    "nr_papers_n_pepi = []\n",
    "\n",
    "p_atleast_f_per_n_epsl = []\n",
    "p_atleast_m_per_n_epsl = []\n",
    "nr_papers_n_epsl = []\n",
    "\n",
    "p_atleast_f_per_n_g3 = []\n",
    "p_atleast_m_per_n_g3 = []\n",
    "nr_papers_n_g3 = []\n",
    "\n",
    "\n",
    "for i in range(1, 6):\n",
    "    \n",
    "    p_atleast_f_per_n_natnatgeo.append(df[(df.Number_authors == i) & ((df.journal == \"Nature\") | (df.journal == \"NatureGeoscience\"))].Prob_atleast_Fauthor.mean())  \n",
    "    p_atleast_m_per_n_natnatgeo.append(df[(df.Number_authors == i) & ((df.journal == \"Nature\") | (df.journal == \"NatureGeoscience\"))].Prob_atleast_Mauthor.mean())  \n",
    "    nr_papers_n_natnatgeo.append(len(df[(df.Number_authors == i) & ((df.journal == \"Nature\") | (df.journal == \"NatureGeoscience\"))]))\n",
    "    \n",
    "    p_atleast_f_per_n_highIF.append(df[(df.Number_authors == i) & ((df.journal == \"Nature\") | (df.journal == \"NatureGeoscience\") | (df.journal == \"Science\"))].Prob_atleast_Fauthor.mean())  \n",
    "    p_atleast_m_per_n_highIF.append(df[(df.Number_authors == i) & ((df.journal == \"Nature\") | (df.journal == \"NatureGeoscience\") | (df.journal == \"Science\"))].Prob_atleast_Mauthor.mean())  \n",
    "    nr_papers_n_highIF.append(len(df[(df.Number_authors == i) & ((df.journal == \"Nature\") | (df.journal == \"NatureGeoscience\") | (df.journal == \"Science\"))]))\n",
    "    \n",
    "    p_atleast_f_per_n_sci.append(df[(df.Number_authors == i) & (df.journal == \"Science\")].Prob_atleast_Fauthor.mean())  \n",
    "    nr_papers_n_sci.append(len(df[(df.Number_authors == i) & ((df.journal == \"Science\"))]))\n",
    "    \n",
    "    p_atleast_f_per_n_jgr.append(df[(df.Number_authors == i) & ((df.journal == \"JGRSolidEarth\"))].Prob_atleast_Fauthor.mean())  \n",
    "    p_atleast_m_per_n_jgr.append(df[(df.Number_authors == i) & ((df.journal == \"JGRSolidEarth\"))].Prob_atleast_Mauthor.mean())  \n",
    "    nr_papers_n_jgr.append(len(df[(df.Number_authors == i) & ((df.journal == \"JGRSolidEarth\"))]))\n",
    "    \n",
    "    p_atleast_f_per_n_gji.append(df[(df.Number_authors == i) & ((df.journal == \"GJI\"))].Prob_atleast_Fauthor.mean())  \n",
    "    p_atleast_m_per_n_gji.append(df[(df.Number_authors == i) & ((df.journal == \"GJI\"))].Prob_atleast_Mauthor.mean())  \n",
    "    nr_papers_n_gji.append(len(df[(df.Number_authors == i) & ((df.journal == \"GJI\"))]))\n",
    "    \n",
    "    p_atleast_f_per_n_bssa.append(df[(df.Number_authors == i) & ((df.journal == \"BSSA\"))].Prob_atleast_Fauthor.mean())  \n",
    "    p_atleast_m_per_n_bssa.append(df[(df.Number_authors == i) & ((df.journal == \"BSSA\"))].Prob_atleast_Mauthor.mean())  \n",
    "    nr_papers_n_bssa.append(len(df[(df.Number_authors == i) & ((df.journal == \"BSSA\"))]))\n",
    "    \n",
    "    p_atleast_f_per_n_t.append(df[(df.Number_authors == i) & ((df.journal == \"Tectp\"))].Prob_atleast_Fauthor.mean())  \n",
    "    p_atleast_m_per_n_t.append(df[(df.Number_authors == i) & ((df.journal == \"Tectp\"))].Prob_atleast_Mauthor.mean())  \n",
    "    nr_papers_n_t.append(len(df[(df.Number_authors == i) & ((df.journal == \"Tectp\"))]))\n",
    "    \n",
    "    p_atleast_f_per_n_srl.append(df[(df.Number_authors == i) & ((df.journal == \"SRL\"))].Prob_atleast_Fauthor.mean())  \n",
    "    p_atleast_m_per_n_srl.append(df[(df.Number_authors == i) & ((df.journal == \"SRL\"))].Prob_atleast_Mauthor.mean())  \n",
    "    nr_papers_n_srl.append(len(df[(df.Number_authors == i) & ((df.journal == \"SRL\"))]))\n",
    "    \n",
    "    p_atleast_f_per_n_gp.append(df[(df.Number_authors == i) & ((df.journal == \"GEOPHYSICS\"))].Prob_atleast_Fauthor.mean())  \n",
    "    p_atleast_m_per_n_gp.append(df[(df.Number_authors == i) & ((df.journal == \"GEOPHYSICS\"))].Prob_atleast_Mauthor.mean())  \n",
    "    nr_papers_n_gp.append(len(df[(df.Number_authors == i) & ((df.journal == \"GEOPHYSICS\"))]))\n",
    "    \n",
    "    p_atleast_f_per_n_grl.append(df[(df.Number_authors == i) & ((df.journal == \"GRL\"))].Prob_atleast_Fauthor.mean())  \n",
    "    p_atleast_m_per_n_grl.append(df[(df.Number_authors == i) & ((df.journal == \"GRL\"))].Prob_atleast_Mauthor.mean())  \n",
    "    nr_papers_n_grl.append(len(df[(df.Number_authors == i) & ((df.journal == \"GRL\"))]))\n",
    "    \n",
    "    p_atleast_f_per_n_pepi.append(df[(df.Number_authors == i) & ((df.journal == \"PEPI\"))].Prob_atleast_Fauthor.mean())  \n",
    "    p_atleast_m_per_n_pepi.append(df[(df.Number_authors == i) & ((df.journal == \"PEPI\"))].Prob_atleast_Mauthor.mean())  \n",
    "    nr_papers_n_pepi.append(len(df[(df.Number_authors == i) & ((df.journal == \"PEPI\"))]))\n",
    "    \n",
    "    p_atleast_f_per_n_epsl.append(df[(df.Number_authors == i) & ((df.journal == \"EPSL\"))].Prob_atleast_Fauthor.mean())  \n",
    "    p_atleast_m_per_n_epsl.append(df[(df.Number_authors == i) & ((df.journal == \"EPSL\"))].Prob_atleast_Mauthor.mean())  \n",
    "    nr_papers_n_epsl.append(len(df[(df.Number_authors == i) & ((df.journal == \"EPSL\"))]))\n",
    "    \n",
    "    p_atleast_f_per_n_g3.append(df[(df.Number_authors == i) & ((df.journal == \"G3\"))].Prob_atleast_Fauthor.mean())  \n",
    "    p_atleast_m_per_n_g3.append(df[(df.Number_authors == i) & ((df.journal == \"G3\"))].Prob_atleast_Mauthor.mean())  \n",
    "    nr_papers_n_g3.append(len(df[(df.Number_authors == i) & ((df.journal == \"G3\"))]))\n",
    "\n",
    "# End ugly crap code\n",
    "\n",
    "print(df.journal.unique())\n",
    "plt.figure(figsize=(9, 12))\n",
    "plt.subplot(211)\n",
    "\n",
    "h0, = plt.plot(n_authors, p_one_f_given_n, \"--\")\n",
    "h1 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_f_per_n_highIF, linewidth=5, alpha=0.5)\n",
    "h3 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_f_per_n_grl, linewidth=5, alpha=0.5)\n",
    "h4 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_f_per_n_gji, linewidth=5, alpha=0.5)\n",
    "h5 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_f_per_n_jgr,linewidth=5, alpha=0.5)\n",
    "h6 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_f_per_n_bssa, linewidth=5, alpha=0.5)\n",
    "h7 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_f_per_n_srl, linewidth=5, alpha=0.5)\n",
    "h8 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_f_per_n_t,  linewidth=5, alpha=0.5)\n",
    "h9 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_f_per_n_gp,linewidth=5, alpha=0.5)\n",
    "h10 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_f_per_n_epsl, linewidth=5, alpha=0.5)\n",
    "h11 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_f_per_n_pepi, linewidth=5, alpha=0.5)\n",
    "h12 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_f_per_n_g3, color=\"b\", linewidth=5, alpha=0.5)\n",
    "h13 = plt.scatter(n_authors_data, p_atleast_f_per_n, color=\"orange\", marker=\"x\", linewidth=10, alpha=0.7)\n",
    "plt.grid()\n",
    "plt.ylabel(\"Probability\")\n",
    "\n",
    "plt.ylim(0.0, 0.75)\n",
    "plt.title(\"Probability at least 1 f\")\n",
    "plt.legend([h0, h1, h3, h4, h5, h6, h7, h8, h9, h10, h11, h12, h13],\n",
    "    [\"Random draw\", \"Nature/Sci/NatGeo\", \"GRL\", \"JGR\", \"GJI\", \"BSSA\", \"SRL\", \"Tectp\", \"Geophys\",\"EPSL\", \"PEPI\", \"G3\", \"Data all\",])\n",
    "plt.xlim(0.5, 5.5)\n",
    "print(\"Papers in bins, BSSA: \", nr_papers_n_bssa)\n",
    "print(\"Papers in bins, Science: \", nr_papers_n_sci)\n",
    "print(\"Papers in bins, Nature / Nature Geosc / Science: \", nr_papers_n_highIF)\n",
    "print(\"Papers in bins, GJI: \", nr_papers_n_gji)\n",
    "print(\"Papers in bins, JGR: \", nr_papers_n_jgr)\n",
    "print(\"Papers in bins, GRL: \", nr_papers_n_grl)\n",
    "print(\"Papers in bins, Geophysics: \", nr_papers_n_gp)\n",
    "print(\"Papers in bins, EPSL: \", nr_papers_n_epsl)\n",
    "print(\"Papers in bins, PEPI: \", nr_papers_n_pepi)\n",
    "print(\"Papers in bins, G3: \", nr_papers_n_g3)\n",
    "\n",
    "plt.subplot(212)\n",
    "h0, = plt.plot(n_authors, p_one_m_given_n, \"--\")\n",
    "h1 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_m_per_n_highIF, linewidth=5, alpha=0.5)\n",
    "h3 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_m_per_n_grl,  linewidth=5, alpha=0.5)\n",
    "h4 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_m_per_n_gji, linewidth=5, alpha=0.5)\n",
    "h5 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_m_per_n_jgr,  linewidth=5, alpha=0.5)\n",
    "h6 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_m_per_n_bssa, linewidth=5, alpha=0.5)\n",
    "h7 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_m_per_n_srl, linewidth=5, alpha=0.5)\n",
    "h8 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_m_per_n_t, linewidth=5, alpha=0.5)\n",
    "h9 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_m_per_n_gp, linewidth=5, alpha=0.5)\n",
    "h10 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_m_per_n_epsl, linewidth=5, alpha=0.5)\n",
    "h11 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_m_per_n_pepi, linewidth=5, alpha=0.5)\n",
    "h12 = plt.scatter(np.arange(1, 6) + (np.random.random(5) - 0.5) / 3.0, p_atleast_m_per_n_g3, color=\"b\", linewidth=5, alpha=0.5)\n",
    "#h13 = plt.scatter(n_authors_data, p_atleast_m_per_n, color=\"orange\", marker=\"x\", linewidth=10, alpha=0.7)\n",
    "\n",
    "plt.grid()\n",
    "plt.ylim(0.6, 1.05)\n",
    "plt.title(\"Probability at least 1 m\")\n",
    "plt.legend([h0, h1, h3, h4, h5, h6, h7, h8, h9, h10, h11, h12, h13],\n",
    "    [\"Random draw\", \"Nature/Sci/NatGeo\", \"GRL\", \"JGR\", \"GJI\", \"BSSA\", \"SRL\", \"Tectp\", \"Geophys\",\"EPSL\", \"PEPI\", \"G3\", \"Data all\",])\n",
    "plt.xlim(0.5, 5.5)\n",
    "plt.xlabel(\"Nr. of authors of the paper\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.savefig(\"p_atleast_per_n_per_journal.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I don't think there is a particularly strong effect of impact factor? It is hard to tell because n is small for Nature etc... overall we just see that female authors have more difficulty to be in predominantly male papers, than male authors to be in predominantly female papers, and that there seems to be a homophily effect jejejeje\n",
    "##### Please help me double check if the argumentation makes sense\n",
    "##### I added random x-offsets to the plotted values for better visibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See the temporal trend of having at least one F or one M in a publication for all journals per year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = df['year'].unique() # a list of unique journal names\n",
    "years.sort()\n",
    "print(years)\n",
    "\n",
    "for i in years: #update values for each journal\n",
    "    cond = df['year']==i\n",
    "    print(\"Number of articles = \", len(df[cond].values), \" for year \", i)\n",
    "    df.loc[cond,'P_atleast_F_year'] = df.loc[cond,'Prob_atleast_Fauthor'].sum()/df[cond].shape[0]\n",
    "    df.loc[cond,'P_atleast_M_year'] = df.loc[cond,'Prob_atleast_Mauthor'].sum()/df[cond].shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y=\"year\", x=\"P_atleast_F_year\",  data=df, order=years, palette='rainbow').set_title('Prob of at least one female all journals per year')\n",
    "plt.xlim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y=\"year\", x=\"P_atleast_M_year\",  data=df, order=years, palette='rainbow').set_title('Prob of at least one male all journals per year')\n",
    "plt.xlim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Female & male percentages per year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To discuss: Here we should make sure that \"male\" only counts \"male\"\n",
    "# last_auth_F_year = df.groupby(['year'])['Last_Author_gend'].apply(lambda x: x[x.str.contains('female')].count())\n",
    "# print(last_auth_F_year)\n",
    "\n",
    "# last_auth_M_year = df.groupby(['year'])['Last_Author_gend'].apply(lambda x: x[x.str.contains('male')].count())\n",
    "# print(last_auth_M_year)\n",
    "\n",
    "# first_auth_F_year = df.groupby(['year'])['First_Author_gend'].apply(lambda x: x[x.str.contains('female')].count())\n",
    "# print(first_auth_F_year)\n",
    "\n",
    "# first_auth_M_year = df.groupby(['year'])['First_Author_gend'].apply(lambda x: x[x.str.contains('male')].count())\n",
    "# print(first_auth_M_year)\n",
    "\n",
    "# first author> someone needs to double check this! \n",
    "for i in years: #update values for each journal\n",
    "    cond = (df['year']==i) & (df[\"First_Author_gend\"] != \"init\")  \n",
    "    # alternatively: Do not remove Init and then probabilities do not sum to 1.\n",
    "    # cond = df['year']==i\n",
    "    \n",
    "    print(\"Number of articles = \", len(df[cond].values), \" for year \", i)\n",
    "    df.loc[cond,'P_first_F_year'] = df.loc[cond,'First_Author_probF'].sum() / len(df.loc[cond])\n",
    "    df.loc[cond,'P_first_M_year'] = (1. - df.loc[cond,'First_Author_probF']).sum() / len(df.loc[cond])\n",
    "    \n",
    "    # uncomment the following line to check if sums up to 1\n",
    "    # print(df.loc[cond, \"P_first_F_year\"].iloc[0:5] + df.loc[cond, \"P_first_M_year\"].iloc[0:5])\n",
    "    print(\"Probability that first author is female: \", df.loc[cond, \"P_first_F_year\"].iloc[0])\n",
    "    print(\"Probability that first author is male: \", df.loc[cond, \"P_first_M_year\"].iloc[0])\n",
    "\n",
    "    \n",
    "    # last author\n",
    "    cond = (df['year']==i) & (df[\"Last_Author_gend\"] != \"init\")  \n",
    "    # alternatively: Do not remove Init and then probabilities do not sum to 1.\n",
    "    # cond = df['year']==i\n",
    "    \n",
    "    #print(\"Number of articles = \", len(df[cond].values), \" for year \", i)\n",
    "    df.loc[cond,'P_last_F_year'] = df.loc[cond,'Last_Author_probF'].sum() / len(df.loc[cond])\n",
    "    df.loc[cond,'P_last_M_year'] = (1. - df.loc[cond,'Last_Author_probF']).sum() / len(df.loc[cond])\n",
    "    \n",
    "    # uncomment the following line to check if sums up to 1\n",
    "    # print(df.loc[cond, \"P_last_F_year\"].iloc[0:5] + df.loc[cond, \"P_last_M_year\"].iloc[0:5])\n",
    "    print(\"Probability that last author is female: \", df.loc[cond, \"P_last_F_year\"].iloc[0])\n",
    "    print(\"Probability that last author is male: \", df.loc[cond, \"P_last_M_year\"].iloc[0])\n",
    "\n",
    "df.to_csv(\"analysis_output_\" + time.strftime(\"%Y-%m-%d.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y=\"year\", x=\"P_first_M_year\",  data=df, order=years, palette='rainbow').set_title('Prob of first author male all journals per year')\n",
    "plt.xlim([0,1])\n",
    "plt.show()\n",
    "\n",
    "sns.barplot(y=\"year\", x=\"P_first_F_year\",  data=df, order=years, palette='rainbow').set_title('Prob of first author female all journals per year')\n",
    "plt.xlim([0,1])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "sns.barplot(y=\"year\", x=\"P_last_M_year\",  data=df, order=years, palette='rainbow').set_title('Prob of last author male all journals per year')\n",
    "plt.xlim([0,1])\n",
    "plt.show()\n",
    "\n",
    "sns.barplot(y=\"year\", x=\"P_last_F_year\",  data=df, order=years, palette='rainbow').set_title('Prob of last author female all journals per year')\n",
    "plt.xlim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rates of change in participation of female authors per year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# converting each value \n",
    "# of column to a string\n",
    "df['year'] = df['year'].astype(float)\n",
    "\n",
    "# running a simple regression\n",
    "mod_p_firstF_year, V= np.polyfit(df.year.values - 2010, df.P_first_F_year.values, 1, cov=True)\n",
    "print(mod_p_firstF_year, np.sqrt(V[0][0]), np.sqrt(V[1][1]))\n",
    "\n",
    "# running a simple regression\n",
    "mod_p_lastF_year, V = np.polyfit(df.year.values - 2010, df.P_last_F_year.values, 1, cov=True)\n",
    "print(mod_p_lastF_year, np.sqrt(V[0][0]), np.sqrt(V[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(y=\"P_first_M_year\", x=\"year\", kind=\"line\",data=df, marker=\"d\");\n",
    "plt.plot(df.year.unique(), 1. - ((df.year.unique() - 2010) * mod_p_firstF_year[0] + mod_p_firstF_year[1]), \":\", color=\"purple\")\n",
    "sns.relplot(y=\"P_last_M_year\", x=\"year\", kind=\"line\", data=df, marker=\"d\");\n",
    "plt.plot(df.year.unique(), 1. - ((df.year.unique() - 2010) * mod_p_lastF_year[0] + mod_p_lastF_year[1]), \":\", color=\"purple\")\n",
    "\n",
    "sns.relplot(y=\"P_first_F_year\", x=\"year\",  kind=\"line\", data=df, marker=\"d\");\n",
    "plt.plot(df.year.unique(), (df.year.unique() - 2010) * mod_p_firstF_year[0] + mod_p_firstF_year[1], \":\", color=\"purple\")\n",
    "sns.relplot(y=\"P_last_F_year\", x=\"year\", kind=\"line\", data=df, marker=\"d\");\n",
    "plt.plot(df.year.unique(), (df.year.unique() - 2010) * mod_p_lastF_year[0] + mod_p_lastF_year[1], \":\", color=\"purple\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all in all this looks pretty linear\n",
    "\n",
    "There does not seem to be a good reason to choose another model than linear increase. \n",
    "\n",
    "The rates of increase per year are weirdly consistent for first and last author: 0.314 % for first authors and 0.318 % for last authors\n",
    "\n",
    "# when would seismology reach parity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_female_first = (year since 2010) * mod0 + mod1\n",
    "# year since 2010 = (0.5 - mod1) / mod0\n",
    "year_parity_first = (0.5 - mod_p_firstF_year[1]) / mod_p_firstF_year[0]\n",
    "print(year_parity_first + 2010)\n",
    "\n",
    "year_parity_last = (0.5 - mod_p_lastF_year[1]) / mod_p_lastF_year[0]\n",
    "print(year_parity_last + 2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oh...in just about 60 - 80 years! \n",
    "While the rate of increase in last authorship is ever so slightly higher, the level of last authorships is lower to begin with, so to reach parity will take a bit longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We should check if the numbers above are biased or are a consequence of female/male author distribution.\n",
    "\n",
    "We can generate synthetic data using the distribution of female/male authors.\n",
    "\n",
    "--> The synthetics have moved to analysis-Synthetics notebook, remain below for not accidentally deleting something useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prob_author(x,y, kind=\"female\", allkinds=\"malefemale\"):\n",
    "    sum = 0\n",
    "    for i, elem in enumerate(x):\n",
    "        if elem not in allkinds:\n",
    "            continue\n",
    "        if elem != kind:\n",
    "            sum += 1 - float(y[i]) \n",
    "        elif elem == kind:\n",
    "            sum += float(y[i])\n",
    "    return sum\n",
    "\n",
    "\n",
    "df['Prob_Fauthor'] = df.apply(lambda x: Prob_author(x.all_genders, x.all_percent, \"female\"), axis=1)\n",
    "df['Prob_Mauthor'] = df.apply(lambda x: Prob_author(x.all_genders, x.all_percent, \"male\"), axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define a random sampler from the distribution of female/male authors:\n",
    "\n",
    "elements = ['female', 'male', 'init']\n",
    "p1 = df['Prob_Fauthor'].sum()/df['Number_authors'].sum() #prob of an author being female\n",
    "p2 = df['Prob_Mauthor'].sum()/df['Number_authors'].sum() #prob of an author being male\n",
    "p3 = 1 - p1 - p2 #prob of an author being init\n",
    "\n",
    "probabilities = [p1, p2 , p3]\n",
    "np.random.choice(elements, 10, p=probabilities) # example: take 10 random samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic genders per each article maintaining the number of authors:\n",
    "\n",
    "dfn = pd.DataFrame()\n",
    "\n",
    "dfn['Synth_genders'] = df['Number_authors'].apply(lambda x: np.random.choice(elements, x, p=probabilities))\n",
    "dfn\n",
    "\n",
    "### Now check for these synthetics the probabilities:\n",
    "\n",
    "# prob having at least one female author\n",
    "\n",
    "def Prob_atleast_Fauthor_synth(x):\n",
    "    prod = 1\n",
    "    for i,elem in enumerate(x):\n",
    "        if elem == 'male':\n",
    "            prod *= 1 \n",
    "        elif elem == 'female':\n",
    "            prod *= 0\n",
    "    return 1 - prod\n",
    "\n",
    "dfn['Prob_atleast_Fauthor_synth'] = dfn.apply(lambda x: Prob_atleast_Fauthor_synth(x.Synth_genders), axis=1)\n",
    "\n",
    "print('Probability of having at least one female author in an article', \n",
    "      dfn['Prob_atleast_Fauthor_synth'].sum()/dfn.shape[0])\n",
    "\n",
    "# prob having at least one male author\n",
    "\n",
    "def Prob_atleast_Mauthor_synth(x):\n",
    "    prod = 1\n",
    "    for i,elem in enumerate(x):\n",
    "        if elem == 'male':\n",
    "            prod *= 0\n",
    "        elif elem == 'female':\n",
    "            prod *= 1\n",
    "    return 1 - prod\n",
    "\n",
    "dfn['Prob_atleast_Mauthor_synth'] = dfn.apply(lambda x: Prob_atleast_Mauthor_synth(x.Synth_genders), axis=1)\n",
    "\n",
    "print('Probability of having at least one male author in an article',\n",
    "      dfn['Prob_atleast_Mauthor_synth'].sum()/dfn.shape[0])\n",
    "\n",
    "\n",
    "### What is the prob of first and last authorships?\n",
    "\n",
    "\n",
    "dfn['First_Author_Fperc_synth'] = dfn['Synth_genders'].apply(lambda x: 1 if x[0]=='female' else 0)\n",
    "dfn['First_Author_Mperc_synth'] = dfn['Synth_genders'].apply(lambda x: 1 if x[0]=='male' else 0)\n",
    "\n",
    "dfn['Last_Author_Fperc_synth'] = dfn['Synth_genders'].apply(lambda x: 1 if x[-1]=='female' else 0)\n",
    "dfn['Last_Author_Mperc_synth'] = dfn['Synth_genders'].apply(lambda x: 1 if x[-1]=='male' else 0)\n",
    "\n",
    "print('First author female:', dfn['First_Author_Fperc_synth'].sum()/dfn.shape[0])\n",
    "print('First author male:', dfn['First_Author_Mperc_synth'].sum()/dfn.shape[0])\n",
    "print('Last author female:', dfn['Last_Author_Fperc_synth'].sum()/dfn.shape[0])\n",
    "print('Last author male:', dfn['Last_Author_Mperc_synth'].sum()/dfn.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "picos",
   "language": "python",
   "name": "picos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
